---
emoji: 🏦
title: Cache와 Caching
date: '2022-12-14 21:12:00'
author: JungSany
tags: blog gatsby JungLog log jung cache caching memo
categories: 개발지식
---

### Cache

- 물건을 일시적으로 저장, 보관하기 위해 사용하는 곳이라는 사전적 의미를 가지고 있는데
- 개발 기술적인 Cache의 뜻으로는 `자주 필요한 데이터나 값`의 복사본을 `일시적`으로 `저장, 보관하기 위해 사용하는 곳`을 말한다.

<br/>

### Caching

- **`Cache`에 데이터나 계산된 결과 값의 복사본을 저장해 둠으로써 전체적인 처리 속도를 향상 시킨다.**
  - 데이터에 직접적으로 접근하는데 걸리는 시간이 오래 걸릴 때
  - 필요한 값을 얻기 위해 계산하는 과정을 생략하고 싶을 때
  - 반복적으로 동일한 결과를 돌려주는 경우(이미지나 썸네일 등)
- `Caching`은 복사본을 이용하는 것이다.
- 하지만 복사본과 `원본이 달라지는 경우`가 생길 수 있으니 `일관성 유지`에 유의해야 한다.

<br/>

### 컴퓨터의 동작원리

![컴퓨터의 동작원리](https://images.velog.io/images/mee9204/post/fb39e719-9435-478b-8044-98d665d30912/hardware_img.png)

| CPU                                     | RAM                           | Hard Drive                           |
| --------------------------------------- | ----------------------------- | ------------------------------------ |
| 중앙처리장치                            | 주기억장치                    | 보조기억장치                         |
| 매우 빠름                               | 빠름                          | 매우 느림                            |
| 기억장치에서 데이터를 받아들여 연산작업 | 전원이 꺼지면 데이터가 지워짐 | 전원이 꺼져도 데이터가 지워지지 않음 |

- RAM은 하드 디스크에서 데이터를 불러오고 CPU는 RAM에 저장되어 있는 데이터를 이용하여 연산 작업을 수행하는 구조이다.
- CPU가 `데이터처리를 위해` RAM과 작업을 진행하게 되는데 `RAM이를 따라가지 못하는 경우` 데이터 `병목현상`이 일어난다.
- 이를 완화하기 위해 CPU와 RAM 사이에 크기는 작지만 속도가 빠른 `Cache Memory`를 두고, 향후 `재사용`할 가능성이 클 것으로 `예상되는 데이터의 복사본을 저장`해둔 후 CPU가 `요청`하는 데이터를 `바로바로 전달`할 수 있게 해준다.

![메모리피라미드](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F991E7C365CBF4BFF01)

- `메인 메모리`는 **DRAM**, `캐시 메모리`는 **SRAM**의 구조를 가지는데, 그 안에는 `트랜지스터`(전류를 제어하는 데 사용하는 전류 구동 반도체 소자)라는 것이 존재한다.
  - **DRAM은 한 셀당 트랜지스터 1개**
  - **SRAM은 한 셀당 트랜지스터 6개**
- 피라미드 구조 이미지에서 위 단계에 있을 수록 빠르고, 가격이 비싸며, 작은 용량을 가지며 CPU와 가까이 위치한다.
- `캐싱`은 CPU와 RAM 사이에서만 사용되는 것이 아니라, 위 피라미드 구조 단계 사이사이에서도 캐싱이 이루어 진다. (CPU → Cache Memory, Cache Memory → RAM 이런식으로 단계별 아래 계층에 대하여 캐싱 작업을 수행)
- **이러한 `메모리 계층 구조의 목적`은 캐싱을 이용하여 빠르고 작은 메모리와 크고 느린 메모리의 장점을 조합해서 크고 빠른 메모리처럼 행동하도록 만들기 위함이다.**

<br/>

### 캐시 동작 원리

- 어떤 부분이 재사용성할 가능성이 큰지 알아보는 방법?
  - 데이터 지역성의 원리를 통하여 데이터 접근이 시간적 혹은 공간적으로 가깝게 일어나는 것을 의미하는데
  - 시간 지역성
    - 특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것
    - 메모리 상의 같은 주소에 여러 차례 읽기 쓰기를 수행할 경우 상대적으로 작은 크기의 캐시를 사용해도 효율성을 높일 수 있음
    - ex) for나 while문의 조건 변수 i
  - 공간 지역성
    - 특정 데이터와 가까운 주소가 순서대로 접근되는 경우
    - 한 메모리 주소에 접근할 때 그 주소뿐 아니라 해당 블록을 전부 캐시에 가져옴
    - 이때 메모리 주소를 오름차순이나 내림차순으로 접근한다면, 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시의 효율성이 크게 향상될 수 있음
    - ex) 배열은 순서대로 접근할 가능성이 크다.
- 캐시 메모리가 해당 데이터를 가지고 있다면 `캐시 히트(캐시 적중)`이라 하며, 해당 데이터가 없어서 메인 메모리에서 가져와야 한다면 `캐시 미스`라고 한다.
- **Write Through 정책**
  - 메인 메모리를 바로 업데이트하는 경우를 말하는데
  - 단순하고 캐시와 메인 메모리의 일관성을 유지할 수 있지만, 매번 바꿔줘야 되므로 느리다는 단점이 존재한다.
- **Write Back 정책**
  - 캐시만 업데이트 하다가, 업데이트된 데이터가 캐시에서 빠지게 될 때 메인 메모리를 업데이트 해주는 정책이다.
  - `업데이트 확인`은 캐시 블록마다 dirty 비트를 추가해야 되며, 데이터가 변경되었다면 dirty 비트가 1로 변경된다. ( 해당 dirty 비트에 대해서는 알아봐야 할 듯 하다.)

<br/>

### 참고링크

우테코 영상을 보고 정리 중

<br/>

```toc

```
